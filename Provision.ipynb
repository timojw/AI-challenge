{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of content:**\n",
    " - [Data Requirements](#data-requirements)\n",
    "   - [Identify Data Types](#identify-data-types)\n",
    "   - [List Data Elements](#list-data-elements)\n",
    "   - [Determine Volume](#determine-volume)\n",
    "   - [Define Quality Standards](#define-quality-standards)\n",
    " - [Data Understanding](#data-understanding)\n",
    "   - [Data Analysis](#data-analysis)\n",
    "   - [Data Visualization](#data-visualization)\n",
    " - [Data Preperation](#data-preperation)\n",
    "   - [Data Cleaning](#data-cleaning)\n",
    "   - [Handeling Missing Data](#handeling-missing-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data = pd.read_csv('./data/openpowerlifting.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Requirements\n",
    "**This first step of the Data Provisioning phase builds upon the Data Sourcing section, where you have defined a basic need for data, in relation to the domain and analytic approach. The purpose of this step is as simple as it is essential: what data do you need to achieve your goal? The key is to be very clear and complete about these requirements, as it serves as the basis for the collection of the data, which is the next step in this phase.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Data Types\n",
    "Data comes in various formats, each requiring distinct processing methods. Here are the primary data types required from a dataset:\n",
    "\n",
    "Numerical Data:\n",
    "- Age: The age of the athletes.\n",
    "- BodyweightKg: Body weight of the athletes in kilograms.\n",
    "- Best3Squat, Best3Bench, Best3Deadlift: Highest lifted weight in their category.\n",
    "  \n",
    "Categorical Data:\n",
    "- Sex: Gender of the athlete.\n",
    "  \n",
    "Text Data:\n",
    "- Not particulary needed in this project.\n",
    "  \n",
    "Image Data:\n",
    "- Not applicable in this project.\n",
    "  \n",
    "Time Series Data:\n",
    "- Not applicable in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Data Elements\n",
    "   \n",
    "Numerical Data:\n",
    "- Age\n",
    "  - Data Type: Numerical\n",
    "  - Units: Years\n",
    "  - Range: 19 to 21\n",
    "- BodyweightKg\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: 68 to 73 kg\n",
    "- Best Lift Attempts (Squat, Bench, Deadlift)\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: Varies\n",
    "  \n",
    "Categorical Data:\n",
    "- Sex\n",
    "  - Data Type: Categorical\n",
    "  - Categories: \"Male\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Volume\n",
    "Given that the initial phase of my project involves relatively simple tasks, a smaller dataset should suffice. This approach aligns with the principle that less complex problems typically require less data for effective training and evaluation of an AI model. However, it's important to acknowledge that in the context of weightlifting, factors such as weight, sex, and age are critical determinants of performance. Even slight variations in these parameters can significantly alter outcomes. Therefore, while starting with a smaller dataset is practical, I may need to progressively include more data to accurately capture the nuanced effects of these specific variables as the model develops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Quality Standards\n",
    "The data I get must be of high quality to ensure the accuracy of our algorithm, which is crucial for precisely predicting weights for my stakeholder. It's essential that this data encompasses all the previously mentioned elements. If any elements are missing or inadequate, I will explore options for either supplementing or omitting them, depending on the specific circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "**Data, analytics, intelligent automation and artificial intelligence have become more mature and are fundamental to the current age of digital transformation. The creation of a data-driven culture helps drive these successful outcomes. However, while most organizations focus on the potential of data-driven technologies our understanding must be carefully cultivated so it becomes a trusted core capability. We need to have a better understanding of the insights data provide using analytics, and how it can improve the way they work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "Effective data analysis in powerlifting hinges on understanding various data attributes and their specific properties. This analysis covers numerical data like age, bodyweight, and lift attempts, providing quantifiable insights into athletic performance. Categorical data, such as sex and equipment used, help in identifying trends across different groups. Textual data, including names and event types, offer contextual understanding. \n",
    "\n",
    "Numerical Data:\n",
    "\n",
    "- Age\n",
    "  - Data Type: Numerical\n",
    "  - Units: Years (halve years when older than 90)\n",
    "  - Range: 1 to 95\n",
    "- BodyweightKg\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: 20 to 237.5 kg\n",
    "- Lift Attempts (Squat, Bench, Deadlift)\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: Varies, including negative values (which represent failed attempts)\n",
    "- Best Lift Attempts (Squat, Bench, Deadlift)\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: Varies\n",
    "  \n",
    "Categorical Data:\n",
    "- Sex\n",
    "  - Data Type: Categorical\n",
    "  - Categories: \"Male\", \"Female\"\n",
    "- Equipment\n",
    "  - Data Type: Categorical\n",
    "  - Categories: Varies (e.g., \"Wraps\", \"Raw\")\n",
    "\n",
    "\n",
    "Text Data:\n",
    "- Name\n",
    "  - Data Type: Text\n",
    "  - Length: Varies\n",
    "- Event\n",
    "  - Data Type: Text\n",
    "  - Length: Short (e.g., \"SBD\" for Squat, Bench, Deadlift)\n",
    "- Division\n",
    "  - Data Type: Text\n",
    "  - Length: Short to medium (e.g., \"F-OR\" for Female Open)\n",
    "- WeightClassKg\n",
    "  - Data Type: Text\n",
    "  - Length: Short (e.g., \"60\" for 60 kg class)\n",
    "- MeetName\n",
    "  - Data Type: Text\n",
    "  - Length: Varies (typically short to medium length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "Data visualization plays an integral role in the analysis process, serving as a vital tool for both discovering and communicating insights. It enables analysts to quickly spot issues such as data entry errors, unusual values, or missing information, ensuring the integrity and reliability of the data. Beyond identifying problems, visualization is key in revealing patterns and trends within the data, often providing initial insights before any complex modeling is applied. Additionally, it's an effective way to communicate these findings, making complex data more understandable and accessible for others. This ability to both uncover and convey information visually is what makes data visualization an indispensable part of data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting the relevant data\n",
    "correlation_data = data[['Age', 'BodyweightKg', 'Sex', 'Best3BenchKg', 'Best3SquatKg', 'Best3DeadliftKg']]\n",
    "\n",
    "# Define a mapping from text to integers\n",
    "sex_mapping = {'F': 0, 'M': 1}\n",
    "\n",
    "# Use the map function to transform the 'Sex' column\n",
    "correlation_data['Sex'] = correlation_data['Sex'].map(sex_mapping)\n",
    "\n",
    "# Correlation for Best Bench Press Performance\n",
    "correlation_bench = correlation_data[['Age', 'BodyweightKg', 'Sex', 'Best3BenchKg']].corr()\n",
    "\n",
    "# Correlation for Best Squat Performance\n",
    "correlation_squat = correlation_data[['Age', 'BodyweightKg', 'Sex', 'Best3SquatKg']].corr()\n",
    "\n",
    "# Correlation for Best Deadlift Performance\n",
    "correlation_deadlift = correlation_data[['Age', 'BodyweightKg', 'Sex', 'Best3DeadliftKg']].corr()\n",
    "\n",
    "# Create heatmaps for each correlation matrix\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.heatmap(correlation_bench, annot=True, cmap='coolwarm', fmt='.2f', ax=ax[0])\n",
    "ax[0].set_title('Correlation: Age, Weight, Sex,  Best Bench')\n",
    "\n",
    "sns.heatmap(correlation_squat, annot=True, cmap='coolwarm', fmt='.2f', ax=ax[1])\n",
    "ax[1].set_title('Correlation: Age, Weight, Sex, Best Squat')\n",
    "\n",
    "sns.heatmap(correlation_deadlift, annot=True, cmap='coolwarm', fmt='.2f', ax=ax[2])\n",
    "ax[2].set_title('Correlation: Age, Weight, Sex, Best Deadlift')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I needed to figure out which Features had the most correlation with my target variables. For that I made correlation charts for the features that made the most sense. As you can see in the heatmaps above the bodyweight and sex have the biggest correlation with the 1RM. Surprisingly the age not so much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out negative values from the best lift columns\n",
    "data = data[(data['Best3SquatKg'] > 0) & (data['Best3BenchKg'] > 0) & (data['Best3DeadliftKg'] > 0)]\n",
    "\n",
    "# Histogram of Age Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Age'], bins=30, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph above I discovered that there is more than enough records on people of the same age as my stakeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out negative values from the best lift columns\n",
    "data = data[(data['Best3SquatKg'] > 0) & (data['Best3BenchKg'] > 0) & (data['Best3DeadliftKg'] > 0)]\n",
    "\n",
    "# Histogram of Age Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['BodyweightKg'], bins=30, kde=True)\n",
    "plt.title('Weight Distribution')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph above I discovered that there is more then enough data on people with roughly the same weight as my stakeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for Best Lift Results per Age\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Squat\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.scatterplot(x='Age', y='Best3SquatKg', data=data)\n",
    "plt.title('Best Squat per Age')\n",
    "plt.ylabel('Squat (kg)')\n",
    "\n",
    "# Bench Press\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.scatterplot(x='Age', y='Best3BenchKg', data=data)\n",
    "plt.title('Best Bench Press per Age')\n",
    "plt.ylabel('Bench Press (kg)')\n",
    "\n",
    "# Deadlift\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.scatterplot(x='Age', y='Best3DeadliftKg', data=data)\n",
    "plt.title('Best Deadlift per Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Deadlift (kg)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above I tried to visualize how age affects the best attempts by the contistants. For me it looks like all 3 exercises have roughly the same curve with few exceptions. Also I noticed that the average for the best squat is significantly higher than the other exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in Best3SquatKg, Best3BenchKg and Best3DeadliftKg columns\n",
    "missing_values = data[['Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']].isnull().sum()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "missing_values.plot(kind='bar')\n",
    "plt.title('Missing Values in BestSquat, BestBench and BestDeadlift')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good to see that there are no missing values in the targets for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in Age, BodyweightKg and Sex columns\n",
    "missing_values = data[['Age', 'BodyweightKg', 'Sex']].isnull().sum()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "missing_values.plot(kind='bar')\n",
    "plt.title('Missing Values in Age and BodyweightKg and Sex')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the graph above it looks like there are a lot of records that have an empty age field. As this is one of the most important features I'm going to try to get more information about that. A way I can try to do so is to try to get their age as an average of the age-group. Which is a range of ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records where 'Age' is missing\n",
    "missing_age_data = data[data['Age'].isna()]\n",
    "\n",
    "# Count the number of records with filled and missing 'AgeClass' fields\n",
    "filled_age_class_count = missing_age_data['AgeClass'].notna().sum()\n",
    "missing_age_class_count = missing_age_data['AgeClass'].isna().sum()\n",
    "\n",
    "# Prepare data for the pie chart\n",
    "age_class_presence_data = {'Filled AgeClass': filled_age_class_count, 'Missing AgeClass': missing_age_class_count}\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(age_class_presence_data.values(), labels=age_class_presence_data.keys(), autopct='%1.1f%%')\n",
    "plt.title('Presence of AgeClass in Records with Missing Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was dissapointed to find out that only 3.3% of people with a missing age had a AgeClass. Converting the AgeClass to their predicted Age, will therefore most likely not make the biggest difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "**Having collected, combined and/or integrated data, does not automatically mean that the data is useful for the next phase Predictions, where it serves as input for modeling. To ensure or improve the data's usefulness for applied data science projects, you need to check its quality and prepare the data for the next phase.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "I have tested for the following possible issues but this dataset seems to be a clean one. There are some blank cells but more about that in the next part about handeling missing data.\n",
    "- Whitespace and new lines\n",
    "- Blank cells\n",
    "- Fixing numbers that aren’t numbers\n",
    "- Structural problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all the values in the specified columns are either numbers or NaN\n",
    "for column in ['Best3BenchKg', 'Best3DeadliftKg', 'Best3SquatKg', 'BodyweightKg', 'Age']:\n",
    "    data[column] = pd.to_numeric(data[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handeling Missing Data\n",
    "Missing values are the Achilles’s heel for a data scientist. If not handled properly, the entire analysis will be futile and provide misleading results which could potentially harm the business stakeholders.\n",
    "\n",
    "As we noted before there are quite a few people with a missing age. We will try to insert an age based on the age-group for those persons that DO have a age-group. For the rest of the entries I have decided to remove them. \n",
    "\n",
    "Because the other features have rather small amounts of missing data I will simply remove those entire people's data from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data\n",
    "\n",
    "# Initial number of individuals with missing age\n",
    "initial_missing_age_count = cleaned_data['Age'].isna().sum()\n",
    "\n",
    "# Number of individuals removed (those who had both Age and AgeClass missing)\n",
    "removed_due_to_missing_ageclass = cleaned_data[\n",
    "    cleaned_data['Age'].isna() & \n",
    "    cleaned_data['AgeClass'].isna()\n",
    "].shape[0]\n",
    "\n",
    "# Number of individuals whose ages were imputed\n",
    "ages_imputed_count = initial_missing_age_count - removed_due_to_missing_ageclass\n",
    "# Filter out entries where both Age and AgeClass are missing\n",
    "cleaned_data = cleaned_data.dropna(subset=['Age', 'AgeClass'], how='all')\n",
    "\n",
    "# Calculate mean age for each AgeClass (excluding NaN values in Age)\n",
    "mean_ages_by_ageclass = cleaned_data.groupby('AgeClass')['Age'].mean()\n",
    "\n",
    "# Assign mean age to missing ages\n",
    "cleaned_data['Age'] = cleaned_data.apply(\n",
    "    lambda row: mean_ages_by_ageclass[row['AgeClass']] if pd.isna(row['Age']) else row['Age'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "initial_missing_age_count, removed_due_to_missing_ageclass, ages_imputed_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NA data\n",
    "cleaned_data = cleaned_data[\n",
    "    (cleaned_data[['BodyweightKg', 'Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']] >= 0).all(axis=1) &\n",
    "    cleaned_data[['BodyweightKg', 'Sex', 'Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']].notna().all(axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Data\n",
    "Beside cleaning, rearranging or reformat data in your data set(s), there a also more intrusive ways to transform data into new or deducted data. Obviously, this is also a form of data preparation, but it can also overlap with the next phase where the data is actually processed, therefore this step is called 'pre-processing' (or processing if there is no further processing involved).\n",
    "\n",
    "I have decided to already filter out people far away from the Stakeholder's bodyweight and people of the different Sex.\n",
    "\n",
    "On the other hand I have decided to not yet filter out based on age, as the correlation with the target variables seemed to be small. For that reason I will continue to experiment with age in the next phase of the project, hence why I will be taking all ages with me to that stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "columns_to_keep = [\n",
    "    'Sex', 'Age', 'BodyweightKg', 'AgeClass',\n",
    "    'Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'Best3SquatKg',\n",
    "    'Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'Best3BenchKg',\n",
    "    'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Best3DeadliftKg'\n",
    "]\n",
    "\n",
    "# Creating a new df with only the selected columns\n",
    "cleaned_data = cleaned_data[columns_to_keep]\n",
    "\n",
    "# Display the first few rows of the cleaned df\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from text to integers\n",
    "sex_mapping = {'F': 0, 'M': 1}\n",
    "\n",
    "# Use the map function to transform the 'Sex' column\n",
    "cleaned_data['Sex'] = cleaned_data['Sex'].map(sex_mapping)\n",
    "\n",
    "# Filtering on bodyweight and sex\n",
    "filtered_data = cleaned_data[\n",
    "    (cleaned_data['BodyweightKg'] >= 68) &\n",
    "    (cleaned_data['BodyweightKg'] <= 75) &\n",
    "    (cleaned_data['Sex'] == 1)\n",
    "]\n",
    "\n",
    "individual_count = filtered_data.shape[0]\n",
    "individual_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
