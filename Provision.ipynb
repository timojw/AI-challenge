{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of content:**\n",
    " - [Data Requirements](#data-requirements)\n",
    "   - [Identify Data Types](#identify-data-types)\n",
    "   - [List Data Elements](#list-data-elements)\n",
    "   - [Determine Volume](#determine-volume)\n",
    "   - [Define Quality Standards](#define-quality-standards)\n",
    " - [Data Understanding](#data-understanding)\n",
    "   - [Data Analysis](#data-analysis)\n",
    "   - [Data Visualization](#data-visualization)\n",
    " - [Data Preperation](#data-preperation)\n",
    "   - [Data Cleaning](#data-cleaning)\n",
    "   - [Handeling Missing Data](#handeling-missing-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "data = pd.read_csv('./data/openpowerlifting.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Requirements\n",
    "**This first step of the Data Provisioning phase builds upon the Data Sourcing section, where you have defined a basic need for data, in relation to the domain and analytic approach. The purpose of this step is as simple as it is essential: what data do you need to achieve your goal? The key is to be very clear and complete about these requirements, as it serves as the basis for the collection of the data, which is the next step in this phase.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Data Types\n",
    "Data comes in various formats, each requiring distinct processing methods. Here are the primary data types required from a dataset:\n",
    "\n",
    "Numerical Data:\n",
    "- Age: The age of the athletes.\n",
    "- BodyweightKg: Body weight of the athletes in kilograms.\n",
    "- Best3Squat, Best3Bench, Best3Deadlift: Highest lifted weight in their category.\n",
    "  \n",
    "Categorical Data:\n",
    "- Sex: Gender of the athlete.\n",
    "  \n",
    "Text Data:\n",
    "- Not particulary needed in this project.\n",
    "  \n",
    "Image Data:\n",
    "- Not applicable in this project.\n",
    "  \n",
    "Time Series Data:\n",
    "- Not applicable in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Data Elements\n",
    "   \n",
    "Numerical Data:\n",
    "- Age\n",
    "  - Data Type: Numerical\n",
    "  - Units: Years\n",
    "  - Range: 19 to 21\n",
    "- BodyweightKg\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: 68 to 73 kg\n",
    "- Best Lift Attempts (Squat, Bench, Deadlift)\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: Varies\n",
    "- Length\n",
    "  - Data Type: Numerical\n",
    "  - Units: Centimeters\n",
    "  - Range: 177 to 187 cm\n",
    "  \n",
    "Categorical Data:\n",
    "- Sex\n",
    "  - Data Type: Categorical\n",
    "  - Categories: \"Male\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Volume\n",
    "Given that the initial phase of my project involves relatively simple tasks, a smaller dataset should suffice. This approach aligns with the principle that less complex problems typically require less data for effective training and evaluation of an AI model. However, it's important to acknowledge that in the context of weightlifting, factors such as weight, sex, and age are critical determinants of performance. Even slight variations in these parameters can significantly alter outcomes. Therefore, while starting with a smaller dataset is practical, I may need to progressively include more data to accurately capture the nuanced effects of these specific variables as the model develops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Quality Standards\n",
    "The data I get must be of high quality to ensure the accuracy of our algorithm, which is crucial for precisely predicting weights for my stakeholder. It's essential that this data encompasses all the previously mentioned elements. If any elements are missing or inadequate, I will explore options for either supplementing or omitting them, depending on the specific circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "**Data, analytics, intelligent automation and artificial intelligence have become more mature and are fundamental to the current age of digital transformation. The creation of a data-driven culture helps drive these successful outcomes. However, while most organizations focus on the potential of data-driven technologies our understanding must be carefully cultivated so it becomes a trusted core capability. We need to have a better understanding of the insights data provide using analytics, and how it can improve the way they work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "Effective data analysis in powerlifting hinges on understanding various data attributes and their specific properties. This analysis covers numerical data like age, bodyweight, and lift attempts, providing quantifiable insights into athletic performance. Categorical data, such as sex and equipment used, help in identifying trends across different groups. Textual data, including names and event types, offer contextual understanding. \n",
    "\n",
    "Numerical Data:\n",
    "\n",
    "- Age\n",
    "  - Data Type: Numerical\n",
    "  - Units: Years (halve years when older than 90)\n",
    "  - Range: 1 to 95\n",
    "- BodyweightKg\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: 20 to 237.5 kg\n",
    "- Lift Attempts (Squat, Bench, Deadlift)\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: Varies, including negative values (which represent failed attempts)\n",
    "- Best Lift Attempts (Squat, Bench, Deadlift)\n",
    "  - Data Type: Numerical\n",
    "  - Units: Kilograms\n",
    "  - Range: Varies\n",
    "  \n",
    "Categorical Data:\n",
    "- Sex\n",
    "  - Data Type: Categorical\n",
    "  - Categories: \"Male\", \"Female\"\n",
    "- Equipment\n",
    "  - Data Type: Categorical\n",
    "  - Categories: Varies (e.g., \"Wraps\", \"Raw\")\n",
    "\n",
    "\n",
    "Text Data:\n",
    "- Name\n",
    "  - Data Type: Text\n",
    "  - Length: Varies\n",
    "- Event\n",
    "  - Data Type: Text\n",
    "  - Length: Short (e.g., \"SBD\" for Squat, Bench, Deadlift)\n",
    "- Division\n",
    "  - Data Type: Text\n",
    "  - Length: Short to medium (e.g., \"F-OR\" for Female Open)\n",
    "- WeightClassKg\n",
    "  - Data Type: Text\n",
    "  - Length: Short (e.g., \"60\" for 60 kg class)\n",
    "- MeetName\n",
    "  - Data Type: Text\n",
    "  - Length: Varies (typically short to medium length)\n",
    "\n",
    "\n",
    "This dataset contains most of the data that I was looking when I was setting up the requirements. The only significant thing that is missing is the length. I will however continue and hope that the lack of this data will not be significantly affecting the predictability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "Data visualization plays an integral role in the analysis process, serving as a vital tool for both discovering and communicating insights. It enables analysts to quickly spot issues such as data entry errors, unusual values, or missing information, ensuring the integrity and reliability of the data. Beyond identifying problems, visualization is key in revealing patterns and trends within the data, often providing initial insights before any complex modeling is applied. Additionally, it's an effective way to communicate these findings, making complex data more understandable and accessible for others. This ability to both uncover and convey information visually is what makes data visualization an indispensable part of data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting the relevant data\n",
    "correlation_data = data[['Age', 'BodyweightKg', 'Sex', 'Best3BenchKg', 'Best3SquatKg', 'Best3DeadliftKg']]\n",
    "\n",
    "# Define a mapping from text to integers\n",
    "sex_mapping = {'F': 0, 'M': 1}\n",
    "\n",
    "# Use the map function to transform the 'Sex' column\n",
    "correlation_data['Sex'] = correlation_data['Sex'].map(sex_mapping)\n",
    "\n",
    "# Correlation for Best Bench Press Performance\n",
    "correlation_bench = correlation_data[['Age', 'BodyweightKg', 'Sex', 'Best3BenchKg']].corr()\n",
    "\n",
    "# Correlation for Best Squat Performance\n",
    "correlation_squat = correlation_data[['Age', 'BodyweightKg', 'Sex', 'Best3SquatKg']].corr()\n",
    "\n",
    "# Correlation for Best Deadlift Performance\n",
    "correlation_deadlift = correlation_data[['Age', 'BodyweightKg', 'Sex', 'Best3DeadliftKg']].corr()\n",
    "\n",
    "# Create heatmaps for each correlation matrix\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.heatmap(correlation_bench, annot=True, cmap='coolwarm', fmt='.2f', ax=ax[0])\n",
    "ax[0].set_title('Correlation: Age, Weight, Sex,  Best Bench')\n",
    "\n",
    "sns.heatmap(correlation_squat, annot=True, cmap='coolwarm', fmt='.2f', ax=ax[1])\n",
    "ax[1].set_title('Correlation: Age, Weight, Sex, Best Squat')\n",
    "\n",
    "sns.heatmap(correlation_deadlift, annot=True, cmap='coolwarm', fmt='.2f', ax=ax[2])\n",
    "ax[2].set_title('Correlation: Age, Weight, Sex, Best Deadlift')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I needed to figure out which Features had the most correlation with my target variables. For that I made correlation charts for the features that made the most sense. As you can see in the heatmaps above the bodyweight and sex have the biggest correlation with the 1RM. Surprisingly the age not so much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out negative values from the best lift columns\n",
    "data = data[(data['Best3SquatKg'] > 0) & (data['Best3BenchKg'] > 0) & (data['Best3DeadliftKg'] > 0)]\n",
    "\n",
    "# Histogram of Age Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Age'], bins=30, kde=True)\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph above I discovered that there is more than enough records on people of the same age as my stakeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out negative values from the best lift columns\n",
    "data = data[(data['Best3SquatKg'] > 0) & (data['Best3BenchKg'] > 0) & (data['Best3DeadliftKg'] > 0)]\n",
    "\n",
    "# Histogram of Age Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['BodyweightKg'], bins=30, kde=True)\n",
    "plt.title('Weight Distribution')\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the graph above I discovered that there is more then enough data on people with roughly the same weight as my stakeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot for Best Lift Results per Age\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Squat\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.scatterplot(x='Age', y='Best3SquatKg', data=data)\n",
    "plt.title('Best Squat per Age')\n",
    "plt.ylabel('Squat (kg)')\n",
    "\n",
    "# Bench Press\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.scatterplot(x='Age', y='Best3BenchKg', data=data)\n",
    "plt.title('Best Bench Press per Age')\n",
    "plt.ylabel('Bench Press (kg)')\n",
    "\n",
    "# Deadlift\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.scatterplot(x='Age', y='Best3DeadliftKg', data=data)\n",
    "plt.title('Best Deadlift per Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Deadlift (kg)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above I tried to visualize how age affects the best attempts by the contistants. For me it looks like all 3 exercises have roughly the same curve with few exceptions. Also I noticed that the average for the best squat is significantly higher than the other exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same method I found out that there are no missing values in the targets for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in Age, BodyweightKg and Sex columns\n",
    "missing_values = data[['Age', 'BodyweightKg', 'Sex']].isnull().sum()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "missing_values.plot(kind='bar')\n",
    "plt.title('Missing Values in Age and BodyweightKg and Sex')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the graph above it looks like there are a lot of records that have an empty age field. As this is one of the most important features I'm going to try to get more information about that. A way I can try to do so is to try to get their age as an average of the age-group. Which is a range of ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter records where 'Age' is missing\n",
    "missing_age_data = data[data['Age'].isna()]\n",
    "\n",
    "# Count the number of records with filled and missing 'AgeClass' fields\n",
    "filled_age_class_count = missing_age_data['AgeClass'].notna().sum()\n",
    "missing_age_class_count = missing_age_data['AgeClass'].isna().sum()\n",
    "\n",
    "# Prepare data for the pie chart\n",
    "age_class_presence_data = {'Filled AgeClass': filled_age_class_count, 'Missing AgeClass': missing_age_class_count}\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(age_class_presence_data.values(), labels=age_class_presence_data.keys(), autopct='%1.1f%%')\n",
    "plt.title('Presence of AgeClass in Records with Missing Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was dissapointed to find out that only 3.3% of people with a missing age had a AgeClass. Converting the AgeClass to their predicted Age, will therefore most likely not make the biggest difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "**Having collected, combined and/or integrated data, does not automatically mean that the data is useful for the next phase Predictions, where it serves as input for modeling. To ensure or improve the data's usefulness for applied data science projects, you need to check its quality and prepare the data for the next phase.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "I have tested for the following possible issues but this dataset seems to be a clean one. There are some blank cells but more about that in the next part about handeling missing data.\n",
    "- Whitespace and new lines\n",
    "- Blank cells\n",
    "- Fixing numbers that aren’t numbers\n",
    "- Structural problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all the values in the specified columns are either numbers or NaN\n",
    "for column in ['Best3BenchKg', 'Best3DeadliftKg', 'Best3SquatKg', 'BodyweightKg', 'Age']:\n",
    "    data[column] = pd.to_numeric(data[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handeling Missing Data\n",
    "Handling missing values is a pivotal challenge in my role as a data scientist. If not managed carefully, it could lead to an analysis that is not only ineffective but also misleading, potentially causing harm to business stakeholders.\n",
    "\n",
    "In the dataset at hand, a significant number of individuals have missing age information. To address this, my approach involves imputing ages for those who have an indicated age group. While this strategy seems reasonable, it is important to acknowledge that it relies on the assumption that the average age of each group accurately represents its members. This could notably alter the data.\n",
    "\n",
    "For individuals lacking both age and age-group information, I have made the decision to exclude their records. It's important to recognize that this choice might introduce a significant bias into the dataset. The reason for the missing age data is unclear, and it could be systematically related to certain age groups. Without a deeper understanding of how the data was collected and the possible reasons behind these omissions, it's challenging to assess the full impact of this decision.\n",
    "\n",
    "Similarly, for other features with minimal missing data, I plan to remove the records of those individuals. While this seems like a straightforward solution, it's important to be aware that this too could affect the representativeness and integrity of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data\n",
    "\n",
    "# Initial number of individuals with missing age\n",
    "initial_missing_age_count = cleaned_data['Age'].isna().sum()\n",
    "\n",
    "# Number of individuals removed (those who had both Age and AgeClass missing)\n",
    "removed_due_to_missing_ageclass = cleaned_data[\n",
    "    cleaned_data['Age'].isna() & \n",
    "    cleaned_data['AgeClass'].isna()\n",
    "].shape[0]\n",
    "\n",
    "# Number of individuals whose ages were imputed\n",
    "ages_imputed_count = initial_missing_age_count - removed_due_to_missing_ageclass\n",
    "# Filter out entries where both Age and AgeClass are missing\n",
    "cleaned_data = cleaned_data.dropna(subset=['Age', 'AgeClass'], how='all')\n",
    "\n",
    "# Calculate mean age for each AgeClass (excluding NaN values in Age)\n",
    "mean_ages_by_ageclass = cleaned_data.groupby('AgeClass')['Age'].mean()\n",
    "\n",
    "# Assign mean age to missing ages\n",
    "cleaned_data['Age'] = cleaned_data.apply(\n",
    "    lambda row: mean_ages_by_ageclass[row['AgeClass']] if pd.isna(row['Age']) else row['Age'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "initial_missing_age_count, removed_due_to_missing_ageclass, ages_imputed_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NA data\n",
    "cleaned_data = cleaned_data[\n",
    "    (cleaned_data[['BodyweightKg', 'Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']] >= 0).all(axis=1) &\n",
    "    cleaned_data[['BodyweightKg', 'Sex', 'Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']].notna().all(axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Data\n",
    "In addition to basic data preparation tasks such as cleaning, rearranging, or reformatting datasets, there are more involved methods of transforming data into new or derived forms. This step, often termed 'pre-processing', is a crucial phase of data preparation. It sometimes overlaps with the actual data processing stage, particularly when no further extensive processing is required.\n",
    "\n",
    "For this project, I have chosen to filter out individuals whose bodyweight significantly deviates from the stakeholder's bodyweight and those of a different sex. The range I've retained is still broad, allowing for flexibility in experimenting with optimal ranges during the prediction phase.\n",
    "\n",
    "Conversely, I have opted not to filter based on age at this stage. The preliminary analysis indicated a minimal correlation between age and the target variables. Therefore, I plan to continue exploring the impact of age in the subsequent project phase, carrying all age data forward for comprehensive experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "columns_to_keep = [\n",
    "    'Sex', 'Age', 'BodyweightKg', 'AgeClass',\n",
    "    'Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'Best3SquatKg',\n",
    "    'Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'Best3BenchKg',\n",
    "    'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'Best3DeadliftKg'\n",
    "]\n",
    "\n",
    "# Creating a new df with only the selected columns\n",
    "cleaned_data = cleaned_data[columns_to_keep]\n",
    "\n",
    "# Display the first few rows of the cleaned df\n",
    "cleaned_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in `columns_to_keep` are essential for a focused analysis in strength sports like powerlifting:\n",
    "\n",
    "1. **Sex**: Important for gender-based performance analysis.\n",
    "2. **Age**: Influences athletic performance; key for age-related analysis.\n",
    "3. **BodyweightKg**: Critical for weight class comparisons and strength-to-weight ratios.\n",
    "4. **AgeClass**: Useful for comparing performance within similar age groups.\n",
    "5. **Squat, Bench, Deadlift Attempts (1Kg, 2Kg, 3Kg)**: Provide insights into an athlete's strategy and consistency across each lift.\n",
    "6. **Best3SquatKg, Best3BenchKg, Best3DeadliftKg**: Indicate the athlete's peak performance in each core lift, essential for ranking and progress analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from text to integers\n",
    "sex_mapping = {'F': 0, 'M': 1}\n",
    "\n",
    "# Use the map function to transform the 'Sex' column\n",
    "cleaned_data['Sex'] = cleaned_data['Sex'].map(sex_mapping)\n",
    "\n",
    "# Filtering on bodyweight and sex\n",
    "filtered_data = cleaned_data[\n",
    "    (cleaned_data['BodyweightKg'] >= 68) &\n",
    "    (cleaned_data['BodyweightKg'] <= 75) &\n",
    "    (cleaned_data['Best3SquatKg'] >= 0) &\n",
    "    (cleaned_data['Best3BenchKg'] >= 0) &\n",
    "    (cleaned_data['Best3DeadliftKg'] >= 0) &\n",
    "    (cleaned_data['Sex'] == 1)\n",
    "]\n",
    "\n",
    "individual_count = filtered_data.shape[0]\n",
    "individual_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have decided to export the dataset to a csv file. That way I can use it in during the Prediction phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory\n",
    "directory = './data/'\n",
    "\n",
    "# File names\n",
    "current_file = 'filtered_data.csv'\n",
    "backup_file = 'filtered_data_backup.csv'\n",
    "\n",
    "# Full paths\n",
    "current_file_path = os.path.join(directory, current_file)\n",
    "backup_file_path = os.path.join(directory, backup_file)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Check if the backup file exists and delete it\n",
    "if os.path.isfile(backup_file_path):\n",
    "    os.remove(backup_file_path)\n",
    "\n",
    "# Check if the current file exists and rename it to the backup\n",
    "if os.path.isfile(current_file_path):\n",
    "    os.rename(current_file_path, backup_file_path)\n",
    "\n",
    "# Save the current dataframe to CSV\n",
    "filtered_data.to_csv(current_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
