{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex   Age  BodyweightKg AgeClass  Squat1Kg  Squat2Kg  Squat3Kg  \\\n",
      "0    0  29.0          59.8    24-34      80.0      92.5     105.0   \n",
      "1    0  29.0          58.5    24-34     100.0     110.0     120.0   \n",
      "2    0  23.0          60.0    20-23    -105.0    -105.0     105.0   \n",
      "3    0  45.0         104.0    45-49     120.0     130.0     140.0   \n",
      "4    0  37.0          74.0    35-39     127.5     135.0     142.5   \n",
      "\n",
      "   Best3SquatKg  Bench1Kg  Bench2Kg  Bench3Kg  Best3BenchKg  Deadlift1Kg  \\\n",
      "0         105.0      45.0      50.0      55.0          55.0        110.0   \n",
      "1         120.0      55.0      62.5      67.5          67.5        130.0   \n",
      "2         105.0      67.5      72.5     -75.0          72.5        132.5   \n",
      "3         140.0      70.0      75.0      80.0          80.0        150.0   \n",
      "4         142.5      72.5      77.5      82.5          82.5        125.0   \n",
      "\n",
      "   Deadlift2Kg  Deadlift3Kg  Best3DeadliftKg  \n",
      "0        120.0        130.0            130.0  \n",
      "1        140.0        145.0            145.0  \n",
      "2       -140.0       -140.0            132.5  \n",
      "3        160.0        170.0            170.0  \n",
      "4        135.0        145.0            145.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './data/filtered_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 486038 entries, 0 to 486037\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Sex              486038 non-null  int64  \n",
      " 1   Age              486038 non-null  float64\n",
      " 2   BodyweightKg     486038 non-null  float64\n",
      " 3   AgeClass         485949 non-null  object \n",
      " 4   Squat1Kg         264359 non-null  float64\n",
      " 5   Squat2Kg         261447 non-null  float64\n",
      " 6   Squat3Kg         254484 non-null  float64\n",
      " 7   Best3SquatKg     486038 non-null  float64\n",
      " 8   Bench1Kg         264315 non-null  float64\n",
      " 9   Bench2Kg         261943 non-null  float64\n",
      " 10  Bench3Kg         254429 non-null  float64\n",
      " 11  Best3BenchKg     486038 non-null  float64\n",
      " 12  Deadlift1Kg      264496 non-null  float64\n",
      " 13  Deadlift2Kg      260505 non-null  float64\n",
      " 14  Deadlift3Kg      249573 non-null  float64\n",
      " 15  Best3DeadliftKg  486038 non-null  float64\n",
      "dtypes: float64(14), int64(1), object(1)\n",
      "memory usage: 59.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "data = data.dropna(subset=['Age', 'BodyweightKg', 'Best3SquatKg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomal Regression\n",
    "Polynomial regression is a form of linear regression in which the relationship between the independent variable xx and the dependent variable yy is modeled as an nth degree polynomial. Unlike simple linear regression, which models the relationship as a straight line, polynomial regression can fit a wide range of curvature in the data. This flexibility makes it particularly useful for modeling datasets where the relationship between variables is not linear but still follows a specific trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Squared Error (MSE)</td>\n",
       "      <td>2223.613651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R-squared (R²)</td>\n",
       "      <td>0.568022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric        Value\n",
       "0  Mean Squared Error (MSE)  2223.613651\n",
       "1            R-squared (R²)     0.568022"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = data[['Age', 'BodyweightKg', 'Sex']]\n",
    "features_to_scale = ['Age', 'BodyweightKg', 'Sex']\n",
    "target = data['Best3SquatKg']\n",
    "scaler = StandardScaler()\n",
    "data[features_to_scale] = scaler.fit_transform(data[features_to_scale])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.1)\n",
    "\n",
    "# Generating polynomial features\n",
    "poly_degree = 2\n",
    "poly_features = PolynomialFeatures(degree=poly_degree)\n",
    "\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Training the model\n",
    "poly_model_bench = LinearRegression()\n",
    "poly_model_bench.fit(X_train_poly, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = poly_model_bench.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "error_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"Mean Squared Error (MSE)\", \"R-squared (R²)\"],\n",
    "    \"Value\": [mse, r2]\n",
    "})\n",
    "\n",
    "error_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Squared Error (MSE)</td>\n",
       "      <td>2217.384135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R-squared (R²)</td>\n",
       "      <td>0.569280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric        Value\n",
       "0  Mean Squared Error (MSE)  2217.384135\n",
       "1            R-squared (R²)     0.569280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = data[['Age', 'BodyweightKg', 'Sex']]\n",
    "features_to_scale = ['Age', 'BodyweightKg', 'Sex']\n",
    "target = data['Best3SquatKg']\n",
    "scaler = StandardScaler()\n",
    "data[features_to_scale] = scaler.fit_transform(data[features_to_scale])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.1)\n",
    "\n",
    "# Generating polynomial features\n",
    "poly_degree = 2\n",
    "poly_features = PolynomialFeatures(degree=poly_degree)\n",
    "\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Training the model\n",
    "poly_model_deadlift = LinearRegression()\n",
    "poly_model_deadlift.fit(X_train_poly, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = poly_model_deadlift.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "error_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"Mean Squared Error (MSE)\", \"R-squared (R²)\"],\n",
    "    \"Value\": [mse, r2]\n",
    "})\n",
    "\n",
    "error_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Squared Error (MSE)</td>\n",
       "      <td>2234.271260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R-squared (R²)</td>\n",
       "      <td>0.564835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric        Value\n",
       "0  Mean Squared Error (MSE)  2234.271260\n",
       "1            R-squared (R²)     0.564835"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = data[['Age', 'BodyweightKg', 'Sex']]\n",
    "features_to_scale = ['Age', 'BodyweightKg', 'Sex']\n",
    "target = data['Best3SquatKg']\n",
    "scaler = StandardScaler()\n",
    "data[features_to_scale] = scaler.fit_transform(data[features_to_scale])\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.1)\n",
    "\n",
    "# Generating polynomial features\n",
    "poly_degree = 2\n",
    "poly_features = PolynomialFeatures(degree=poly_degree)\n",
    "\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "# Training the model\n",
    "poly_model_squat = LinearRegression()\n",
    "poly_model_squat.fit(X_train_poly, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = poly_model_squat.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "error_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"Mean Squared Error (MSE)\", \"R-squared (R²)\"],\n",
    "    \"Value\": [mse, r2]\n",
    "})\n",
    "\n",
    "error_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Squared Error (MSE)</td>\n",
       "      <td>2175.970907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Root Mean Squared Error (RMSE)</td>\n",
       "      <td>46.647303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean Absolute Error (MAE)</td>\n",
       "      <td>35.698364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R-squared (R²)</td>\n",
       "      <td>0.576190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Metric        Value\n",
       "0        Mean Squared Error (MSE)  2175.970907\n",
       "1  Root Mean Squared Error (RMSE)    46.647303\n",
       "2       Mean Absolute Error (MAE)    35.698364\n",
       "3                  R-squared (R²)     0.576190"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Setting up a pipeline with PolynomialFeatures and Ridge Regression\n",
    "pipe = Pipeline([\n",
    "    ('polynomial_features', PolynomialFeatures()),\n",
    "    ('ridge_regression', Ridge())\n",
    "])\n",
    "\n",
    "# Parameters for GridSearchCV\n",
    "params = {\n",
    "    'polynomial_features__degree': [1, 2, 3, 4, 5],  # Trying different polynomial degrees\n",
    "    'ridge_regression__alpha': [0.001, 0.01, 0.1, 1, 10, 100]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Using GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(pipe, params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Training the model with the best parameters\n",
    "best_poly_degree = best_params['polynomial_features__degree']\n",
    "best_alpha = best_params['ridge_regression__alpha']\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=best_poly_degree)\n",
    "X_train_poly = poly_features.fit_transform(X_train)\n",
    "X_test_poly = poly_features.transform(X_test)\n",
    "\n",
    "best_model = Ridge(alpha=best_alpha)\n",
    "best_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = best_model.predict(X_test_poly)\n",
    "\n",
    "# New evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "error_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"Mean Squared Error (MSE)\", \"Root Mean Squared Error (RMSE)\", \"Mean Absolute Error (MAE)\", \"R-squared (R²)\"],\n",
    "    \"Value\": [mse, rmse, mae, r2]\n",
    "})\n",
    "\n",
    "error_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error (MSE):**\n",
    "\n",
    "What It Measures: MSE calculates the average of the squares of the errors or deviations—that is, the difference between the actual and predicted values.\n",
    "\n",
    "Importance: It's useful for quantifying the magnitude of errors in prediction. Since it squares the errors, larger errors are weighted more heavily, making it particularly sensitive to outliers.\n",
    "\n",
    "Range: 0 to ∞.\n",
    "\n",
    "Interpretation: A lower MSE is better. A value of 0 indicates perfect predictions with no errors, which is the ideal scenario. Higher values indicate larger average errors in prediction.\n",
    "\n",
    "\n",
    "**Root Mean Squared Error (RMSE):**\n",
    "\n",
    "What It Measures: RMSE is the square root of the MSE.\n",
    "\n",
    "Importance: It's in the same units as the target variable, making it more interpretable than MSE. Like MSE, it gives higher weight to larger errors and is sensitive to outliers.\n",
    "\n",
    "Range: 0 to ∞.\n",
    "\n",
    "Interpretation: Like MSE, a lower RMSE is better, with 0 being the ideal case. RMSE increases with the magnitude of prediction error.\n",
    "\n",
    "**Mean Absolute Error (MAE):**\n",
    "\n",
    "What It Measures: MAE calculates the average of the absolute differences between predicted values and actual values.\n",
    "\n",
    "Importance: It provides a straightforward interpretation of average error magnitude. Unlike MSE and RMSE, MAE doesn't heavily penalize larger errors, making it more robust to outliers.\n",
    "\n",
    "Range: 0 to ∞.\n",
    "\n",
    "Interpretation: Lower values of MAE are better, with 0 indicating perfect predictions. MAE provides a direct measure of average prediction error magnitude.\n",
    "\n",
    "**R-squared (R²):**\n",
    "\n",
    "What It Measures: R², also known as the coefficient of determination, measures the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
    "\n",
    "Importance: It provides an indication of the goodness of fit of a set of predictions to the actual values. An R² of 1 indicates perfect correlation, while an R² of 0 indicates no correlation. R² is a relative measure of fit, useful for comparing different models.\n",
    "\n",
    "Range: -∞ to 1.\n",
    "\n",
    "Interpretation: Higher values are better. A value of 1 indicates perfect prediction accuracy. However, a value of 0 or lower indicates that the model performs no better (or worse) than simply predicting the mean of the target variable for all observations. R² can be negative when the model is exceedingly poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "Random Forest is an ensemble learning method, particularly effective for regression tasks. It operates by constructing multiple decision trees during training and outputting the mean or average prediction of the individual trees. This approach helps in reducing overfitting, a common problem in decision tree models, and improves the predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3661306787.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    x = data[['Age', 'BodyweightKg', 'Sex']]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "  \n",
    "  # Define the features and the target\n",
    "  x = data[['Age', 'BodyweightKg', 'Sex']]\n",
    "  y = data['Best3SquatKg']\n",
    "  \n",
    "  # Spliting the data\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "  \n",
    "  # Initialize the Random Forest Regressor\n",
    "  rf_regressor = RandomForestRegressor(n_estimators=100)\n",
    "  \n",
    "  # Train the model\n",
    "  rf_regressor.fit(X_train, y_train)\n",
    "  \n",
    "  # Predict on the test set\n",
    "  y_pred = rf_regressor.predict(X_test)\n",
    "  \n",
    "  # Evaluate the model\n",
    "  mse = mean_squared_error(y_test, y_pred)\n",
    "  r2 = r2_score(y_test, y_pred)\n",
    "  \n",
    "  # Creating a DataFrame to display the values\n",
    "  error_metrics = pd.DataFrame({\n",
    "      \"Metric\": [\"Mean Squared Error (MSE)\", \"R-squared (R²)\"],\n",
    "      \"Value\": [mse, r2]\n",
    "  })\n",
    "  \n",
    "  error_metrics\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Regression\n",
    "MLP Regression refers to the application of a Multi-Layer Perceptron, a class of feedforward artificial neural network, to regression tasks. MLP consists of multiple layers of nodes, simulating a biological neural network, which makes it highly effective in capturing complex and non-linear relationships in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timom\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [97208, 48604]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate Mean Squared Error\u001b[39;00m\n\u001b[0;32m     21\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, predictions)\n\u001b[1;32m---> 22\u001b[0m r2 \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Creating a DataFrame to display the values\u001b[39;00m\n\u001b[0;32m     25\u001b[0m error_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error (MSE)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR-squared (R²)\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m: [mse, r2]\n\u001b[0;32m     28\u001b[0m })\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:989\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    849\u001b[0m     {\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    869\u001b[0m ):\n\u001b[0;32m    870\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m    -inf\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_regression.py:99\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m        correct keyword.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    101\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [97208, 48604]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X = data[['Age', 'BodyweightKg', 'Sex']]\n",
    "y = data['Best3SquatKg']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create the MLPRegressor model\n",
    "model = MLPRegressor(hidden_layer_sizes=(200, 200, 200), activation='relu', \n",
    "                     solver='adam', max_iter=500, random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Creating a DataFrame to display the values\n",
    "error_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"Mean Squared Error (MSE)\", \"R-squared (R²)\"],\n",
    "    \"Value\": [mse, r2]\n",
    "})\n",
    "\n",
    "error_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It appears that the models I've experimented with aren't performing as expected. Despite various attempts and configurations, the accuracy remains unsatisfactorily low, and the last model even yielded a negative R² score, which suggests there might be some issues in my approach. This leads me to believe that our current dataset might be insufficient for accurate predictions. Incorporating additional features, such as muscle mass, nutritional habits, and body length, could potentially enhance the model's predictive power and provide a more comprehensive understanding of the factors influencing the outcomes. Other ways could be to use Grid Search or Random Search for hyperparameter tuning to improve the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model_squat.pkl', 'wb') as file:\n",
    "    pickle.dump(poly_model_squat, file)\n",
    "\n",
    "with open('model_bench.pkl', 'wb') as file:\n",
    "    pickle.dump(poly_model_bench, file)\n",
    "\n",
    "with open('model_deadlift.pkl', 'wb') as file:\n",
    "    pickle.dump(poly_model_deadlift, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
